% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
%\documentclass[runningheads]{llncs}
\documentclass[preprint,10pt]{sigplanconf}

% packages
\usepackage{xspace}
\usepackage{ifthen}
\usepackage{amsbsy}
\usepackage{amssymb}
\usepackage{balance}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{needspace}
\usepackage{microtype}
\usepackage{bold-extra}
\usepackage{array}
\usepackage{epstopdf}


% references
\usepackage[colorlinks]{hyperref}
\usepackage[all]{hypcap}
\setcounter{tocdepth}{2}
\hypersetup{
	colorlinks=true,
	urlcolor=black,
	linkcolor=black,
	citecolor=black,
	plainpages=false,
	bookmarksopen=true}

\def\chapterautorefname{Chapter}
\def\appendixautorefname{Appendix}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Section}
\def\figureautorefname{Figure}
\def\tableautorefname{Table}
\def\listingautorefname{Listing}

% source code
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{listings}
\definecolor{source}{gray}{0.9}
\lstset{
	language={},
	% characters
	tabsize=3,
	upquote=true,
	escapechar={!},
	keepspaces=true,
	breaklines=true,
	alsoletter={\#:},
	breakautoindent=true,
	columns=fullflexible,
	showstringspaces=false,
	basicstyle=\footnotesize\ttfamily,
	% background
	frame=single,
    framerule=0pt,
	backgroundcolor=\color{source},
	% numbering
	numbersep=5pt,
	numberstyle=\tiny,
	numberfirstline=true,
	% captioning
	captionpos=b,
	% formatting (html)
	moredelim=[is][\textbf]{<b>}{</b>},
	moredelim=[is][\textit]{<i>}{</i>},
	moredelim=[is][\color{red}\uwave]{<u>}{</u>},
	moredelim=[is][\color{red}\sout]{<del>}{</del>},
	moredelim=[is][\color{blue}\underline]{<ins>}{</ins>}}
\newcommand{\ct}{\lstinline[backgroundcolor=\color{white},basicstyle=\footnotesize\ttfamily]}
\newcommand{\lct}[1]{{\small\tt #1}}

% tikz
% \usepackage{tikz}
% \usetikzlibrary{matrix}
% \usetikzlibrary{arrows}
% \usetikzlibrary{external}
% \usetikzlibrary{positioning}
% \usetikzlibrary{shapes.multipart}
% 
% \tikzset{
% 	every picture/.style={semithick},
% 	every text node part/.style={align=center}}
% \tikzexternalize[prefix=figures/]{quality}

% proof-reading
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\newcommand{\ra}{$\rightarrow$}
\newcommand{\ugh}[1]{\textcolor{red}{\uwave{#1}}} % please rephrase
\newcommand{\ins}[1]{\textcolor{blue}{\uline{#1}}} % please insert
\newcommand{\del}[1]{\textcolor{red}{\sout{#1}}} % please delete
\newcommand{\chg}[2]{\textcolor{red}{\sout{#1}}{\ra}\textcolor{blue}{\uline{#2}}} % please change
\newcommand{\chk}[1]{\textcolor{ForestGreen}{#1}} % changed, please check

% comments \nb{label}{color}{text}
\newboolean{showcomments}
\setboolean{showcomments}{true}
\ifthenelse{\boolean{showcomments}}
	{\newcommand{\nb}[3]{
		{\colorbox{#2}{\bfseries\sffamily\scriptsize\textcolor{white}{#1}}}
		{\textcolor{#2}{\sf\small$\blacktriangleright$\textit{#3}$\blacktriangleleft$}}}
	 \newcommand{\version}{\emph{\scriptsize$-$Id$-$}}}
	{\newcommand{\nb}[2]{}
	 \newcommand{\version}{}}
\newcommand{\rev}[2]{\nb{Reviewer #1}{red}{#2}}
\newcommand{\ab}[1]{\nb{Alexandre}{blue}{#1}}
\newcommand{\sv}[1]{\nb{Santiago}{orange}{#1}}

% graphics: \fig{position}{percentage-width}{filename}{caption}
\DeclareGraphicsExtensions{.png,.jpg,.pdf,.eps,.gif}
\graphicspath{{figures/}}
\newcommand{\fig}[4]{
	\begin{figure}[#1]
		\centering
		\includegraphics[width=#2\textwidth]{#3}
		\caption{\label{fig:#3}#4}
	\end{figure}}

% abbreviations
\newcommand{\ie}{\emph{i.e.,}\xspace}
\newcommand{\eg}{\emph{e.g.,}\xspace}
\newcommand{\etc}{\emph{etc.}\xspace}
\newcommand{\etal}{\emph{et al.}\xspace}

% lists
\newenvironment{bullets}[0]
	{\begin{itemize}}
	{\end{itemize}}

\newcommand{\seclabel}[1]{\label{sec:#1}}
\newcommand{\secref}[1]{Section~\ref{sec:#1}\xspace}
\newcommand{\co}[1]{{\sf #1}}


% D O C U M E N T
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\begin{document}

% T I T L E
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\title{Aspect-based refactoring}

\authorinfo{Santiago Vidal}
	{ISISTAN Research Institute, Faculty of Sciences, UNICEN University, Campus Universitario, Tandil, Buenos Aires, Argentina, Also CONICET}
	{svidal@exa.unicen.edu.ar}
\authorinfo{Claudia Marcos} 
	{ISISTAN Research Institute, Faculty of Sciences, UNICEN University, Campus Universitario, Tandil, Buenos Aires, Argentina, Also CIC}
	{cmarcos@exa.unicen.edu.ar}
\authorinfo{Alexandre Bergel}
	{PLEIAD Lab, Department of Computer Science (DCC), University of Chile, Santiago, Chile}
	{abergel@dcc.uchile.cl}
\authorinfo{Gabriela Ar\'evalo}


\maketitle

% A B S T R A C T
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\begin{abstract}
an abstract
\end{abstract}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Introduction}\seclabel{introduction}

The story to tell in this paper is the following one:
1) We have the actual Mondrian code
2) Santiago have extracted the CC into pragmas
3) He has identified different possible pragmas. Here some patterns could be identified based on the code (That's the POINT of the paper)
4) Once we have the pragmas, we can think of an injection machine to produce new code.
This new code is semantically equivalent to the original one, but not syntactically the same. This is not so important since all the large set of Mondrian unit tests has the last word on it.

Then the core of the paper will be the Different patterns of hand written code that are rewritten (refactored?) with pragmas 

justificar el xq se quiere refactorizar los cache 

\ab{what is the link with your previous work? Is there some hypothesis that you validate with the experiment on Mondrian?}

\ab{this is just a try, we will probably refine that later} This work presented in this paper makes the following contributions:
\begin{itemize}
\item Identification and composition of pattern for memoization techniques
\item Associating code quality metrics and AOP-based refactoring. \ab{refactoring Mondrian increases its quality (we can use macCabe complexity, number of lines of code, number of methods, ...)}
\item General technique of implementing memoization with AOP
\end{itemize}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Making Mondrian Evolve}\seclabel{problem}

This section describes a maintenance problem we have faced when development the Mondrian visualization engine.

%:=========
\subsection{Turning Mondrian into a framework}

Mondrian\footnote{\url{http://www.moosetechnology.org/tools/mondrian}}~\cite{Meye06a} is an agile visualization library. A domain specific language is provided to easily define interactive visualizations.
Visualizations are structured along a graph structured, made of possibly nested nodes and edges. Mondrian is a crucial component which is used in more than a dozen of independent projects. To meet clients performance requirements, Mondrian authors are paying a great attention to provide fast and scalable rendering. To that purpose, Mondrian contains a number of cache to avoid redundant code executions.

Mondrian is now on the verge to become a visualization engine framework versus a library as it is currently. Mondrian is now used in situations that were not originally planned. For example, Mondrian has been used to visualize the real-time behavior of animated robots\footnote{\url{http://www.squeaksource.com/Calder.html}}, 3D visualizations\footnote{\url{http://www.squeaksource.com/Klotz.html}}, whereas Mondrian has been originally designed to visualize software source code using plain 2D drawing~\cite{Lanz03d}. The caches that are intensively used when visualizing software are not useful and may even be a source of slowdown and complexity when visualizing animated robots. 

The future Mondrian framework must offer the possibility of selectively using and combining caches.

%:=========
\subsection{Memoization}

Memoization is an optimization technique used to speed up an application by making calls avoid repeating the similar previous computation\footnote{\url{http://www.tfeb.org/lisp/hax.html\#MEMOIZE}}. Consider the method \ct{absoluteBounds} that any Mondrian element can answer to. This method determines the circumscribed rectangle of the graphical element:

\begin{lstlisting} 
MOGraphElement>>absoluteBounds
	<b>absoluteBoundsCache 
		ifNotNil: [ ^ absoluteBoundsCache ].</b>
	^ <b>absoluteBoundsCache := 
		</b>self shape absoluteBoundsFor: self
\end{lstlisting}

The method \ct{absoluteBoundsFor:} realizes heavy computation to determine what the smallest rectangle that contains all the nested elements. Since this method does not perform any global side effect, the class \ct{MOGraphElement} defines an instance variable called \ct{absoluteBoundsCache} which is initialized at the first invocation of \ct{absoluteBounds}. Subsequent invocation will therefore use the result previously computed. 

Obviously, the variable \ct{absoluteBoundsCache} needs to be set to \ct{nil} when the structure of the element is modified (\eg adding a new nested node, drag and dropping).

%Implementing a memoization is not always that simple. 

%:=========
\subsection{Problem.}

Mondrian intensively use memoization for most of it computation. A user-performed interaction that leads to an update of the visualization invalidate the visualization. These memoization have were gradually introduced over the long development of Mondrian (which started in 2006). Each unpredicted usage leaded to a performance problem was has been solved using a new memoization. There is about 32 memoizations in the current version of Mondrian.

These caches have been shaped along the common usage of Mondrian. Visualizations produced in Mondrian are \emph{all} static, employ colored geometrical objects and interactions are offered by simply on these objects.

Extending the range of applications for Mondrian invalidate some of the caches. For example \ct{absoluteBoundsCache} has no meaning in the three-dimensional version of Mondrian since the circumscribed rectangle is meaningful only with two dimentions.

\ab{here}
Modularizing caches cannot be realizing without loosing performances.
Currently, the caches are implemented by means of dedicated instance variables
 defined in the \ct{MOGraphElement} class. That is to say, for each
new cache that is added, a variable must be defined. The basic functionalities
of the caches are store/get a value and reset. The goal of
the refactoring is the extraction of the \emph{Cache Concern}
by means of the creation of a specific class to delegate the behavior
of the caches, it must have these functionalities. For example, could
be used a strategy which uses a class containing a collection of caches
and each cache can contain different types of items (as is shown in
Fig. \ref{fig:Cache-behaviour-delegation.}). In this case, all the
cache variables and the fragments of code of the methods in which
they were used were encapsulated using the \emph{Cache} class and
creating a suitable \emph{CacheableItem}. In \emph{MOGraphElement}
hierarchy only remain a reference to the \emph{Cache} class that contains
all the caches. However, this kind of modularization looses performances
because the access to the cache variable is not direct. This causes
a delay when attempting to access the values that keep the caches.
So, the separation of this concern is not a trivial problem. Specifically,
when this solution the caches mechanism was 3 to 10 times slower,
being the delay proportional to the number of elements.

%
\begin{figure*}
\begin{centering}
\includegraphics[bb=27bp 615bp 338bp 762bp,scale=0.97]{CacheMechanisms} 
\par\end{centering}

\caption{Cache behavior delegation.\label{fig:Cache-behaviour-delegation.}}

\end{figure*}


%:=========
\subsection{Requirement for refactoring}

\begin{itemize}
\item to understand where the cache are defined and used
\item no cost must be incurred, else it defeats the whole purpose of the work
\item Readability must not be reduced
\end{itemize}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Refactoring}\seclabel{refactoring}


The goal of the refactoring is the separation of the \emph{Cache
Concern} from the main class of \emph{Mondrian}: \emph{MOGraphElement}
and its subclasses (\emph{MOEdge}, \emph{MONode}, and \emph{MORoot}, totaling more than 235 methods and 1000 number of lines of codes).
The refactoring process begins with the identification of the caches.
This initial identification of the caches is done with the information
provided by the developers of Mondrian and it lies in to know the
variables related to the caches and the places where they are used.
Nine different caches are found in Mondrian: \emph{cacheShapeBounds},
\emph{cacheForm}, \emph{boundsCache}, \emph{absoluteBoundsCache},
\emph{elementsToDisplayCache}, \emph{lookupNodeCache}, \emph{cacheFromPoint},
\emph{cacheToPoint}, and \emph{cacheBounds}. Each of them has a different
internal structure according on what is stored. After this initial
identification, the fragment of codes in which the caches are used
are grouped together based on the purpose of its use. A cache is associated with the following actions: 
\begin{itemize}
\item Initialize and reset the cache
\item Retrieve the cache value
\item Store data in the cache
\end{itemize}
\ab{what is a group and a subgroup?}
\sv{Los grupos son: \{Initialize, Retrieve, Store\} y los subgrupos son aquellas lineas de codigo que tienen el mismo patron para cada uno de los elementos  de estos grupos. Por emplo, los sugrupos de Initialize son Lazy initialization y cache Initialization.
La verdad que el concepto de grupo-subgrupo no es algo importante o que sume valor. Creo que simplemente podemos poner que la division en grupos permitio detectar patrones.}\ab{I see. But why these groups and subgroups are not apparent in Figure 3? Shouldn't we have a class Initialization with two subclasses, LazyInitialization and CacheInitialization?}
The task of group the fragments of code of the different caches is
achieved with the goal of identifying possible strategies for refactoring.
In this line, some subgroups of similar functionalities are found.
These subgroups allows the identification of code patterns that are
repeated in the use of the caches. Once the patterns are identified,
a refactoring strategy is applied. These steps are described in the
following subsections.


\subsection{Pattern Description\label{sub:Pattern-Identification}}

This section presents the 5 code patterns we identified. 
Each pattern is described with a relevant typical occurrence,
the number of occurrences of the pattern and a code example.

\paragraph{Reset Cache.} A cache need to be invalidated when its content has to be actualized. We refer to this action as reset. The reset structure is \emph{cache:=resetValue} where
\emph{resetValue} depends on the cache internal structure. Typically,
the \emph{resetValue} is nil or a new of a kind of Dictionary object.
Eighteen occurrences of this pattern are found in the Mondrian code. 
We found that in some occurrences the reset of the caches is performed before the logic of the method, and other methods in which the reset must be done after. 
Next, the method \emph{resetCache} is presented as an example. In
this method the \emph{Reset Cache} pattern is repeated in four occasions
to reset the caches \emph{boundsCache}, \emph{absoluteBoundsCache},
\emph{cacheShapeBounds}, and \emph{elementsToDisplayCache}. In this case, the reset of the caches can be done before or after the execution of the methods \emph{resetElementsToLookup} and  \emph{resetMetricCaches}.

\begin{lstlisting} 
MOGraphElement>>resetCache 
	self resetElementsToLookup.
	boundsCache := nil. 
	absoluteBoundsCache := nil. 
	cacheShapeBounds :=SmallDictionary new. 
	elementsToDisplayCache := nil. 
	self resetMetricCaches
\end{lstlisting}

\paragraph{Lazy initialization.} In some situations it is not relevant to initialize the cache before it is actually need. This pattern shows
the situation in which a verification is accomplished before access
to a cache with the goal of avoid possible exceptions when the cache
is nil. Typically, the structure of this pattern is: \emph{if (cache==nil)
cache:=newValue. return cache}. Five occurrences of this pattern are
found in the Mondrian code. Next, the method \emph{bounds} is presented
as an example in which boundsCache is accessed.

\begin{lstlisting} 
MOEdge>>bounds  
	^ boundsCache ifNil:[boundsCache:= self shape computeBoundsFor: self ]. 
\end{lstlisting}

\paragraph{Cache Initialization.} this pattern represents a situation in
which a value is assigned to a cache. The structure of the pattern
is only an assignation: cache:=\emph{aValue}. This pattern is found
in three occasions. Next, the method \emph{cacheCanvas} is presented
as an example in which a value is assigned to cacheForm.

\begin{lstlisting} 
MOGraphElement>>cacheCanvas: aCanvas 
	cacheForm:= aCanvas form copy: ((self bounds origin + aCanvas origin 
	- (1@1)) extent: (self bounds extent + (2@2))). 
\end{lstlisting}

\paragraph{Return Cache.} this pattern shows the situation in which a cache
is accessed. The structure of the pattern is the return of the cache:
\emph{return cache}. This pattern is found in four occasions. Next,
the method \emph{shapeBounds} is presented as an example in which
cacheShapeBounds is accessed.

\begin{lstlisting} 
MOGraphElement>>shapeBounds  
	^ cacheShapeBounds
\end{lstlisting}

\paragraph{Cache Loaded.} this pattern checks whether one cache or more
are initialized or conversely, if they are not nil. So, the structure of the
pattern for a single cache is \emph{cache != nil}. This pattern is
found in two occasions. Next the method \emph{isCacheLoaded} is presented
as an example of this pattern.

\begin{lstlisting} 
MOGraphElement>>isCacheLoaded 
	^cacheForm notNil. 
\end{lstlisting}

Fig. \ref{fig:Pattern-locations-in} shows the distribution of the caches over the main Mondrian classes.%
\begin{figure*}
\begin{centering}
\includegraphics[bb=186bp 306bp 497bp 644bp,scale=0.9]{PatternLocation} 
\par\end{centering}

\caption{Pattern locations in MOGraphElement hierarchy.\label{fig:Pattern-locations-in}}

\end{figure*}


Additionally, Table \ref{tab:Cache-Concern-scattering} presents a
summary of the occurrences of each pattern in the MOGraphElement hierarchy,
the methods involved in each pattern, and the caches related with
a pattern.

%
\begin{table*}
\begin{centering}
\begin{tabular}{|p{2.5cm}|c|c|p{3.5cm}|}
\hline 
Cache  & Occurrences  & Methods involved  & Caches involved\tabularnewline
\hline
\hline 
\emph{Reset Cache}  & 18 & 10 & boundsCache, absoluteBoundsCache, cacheShapeBounds, elementsToDisplayCache,
cacheForm, cacheFromPoint, cacheToPoint\tabularnewline
\hline 
\emph{Lazy Initialization}  & 5 & 5 & elementsToDisplayCache, absoluteBoundsCache, boundsCache, cacheBounds\tabularnewline
\hline 
\emph{Cache Initialization}  & 3 & 3 & cacheForm, cacheFromPoint, cacheToPoint\tabularnewline
\hline 
\emph{Return Cache}  & 4 & 4 & cacheShapeBounds, cacheForm, cacheFromPoint, cacheToPoint\tabularnewline
\hline 
\emph{Cache Loaded} & 2 & 2 & cacheForm, cacheFromPoint, cacheToPoint\tabularnewline
\hline 
Total  & 32 & 24 & \multicolumn{1}{c}{}\tabularnewline
\cline{1-3} 
\end{tabular}
\par\end{centering}

\caption{Cache Concern scattering summary.\label{tab:Cache-Concern-scattering}}

\end{table*}



\subsection{Refactoring Strategy}

Once the code patterns are identified, strategies to refactor them
are established. The goal of the refactorization is the extraction of these patterns from the main code without changing the behavior of the system. The main constraint to refactoring the code is the
preservation of a good performance of the cache mechanism.

Several alternatives were explored to encapsulate the \emph{Cache
Concern}. For example, one of the explored mechanisms was the separation
of the concern by means of the definition of an exclusive class for
managing caches. While this solution provided a good modular design,
it introduced indirections to access to the caches (\secref{problem}).
Indirections caused a poor performance that slows down response times
of the cache mechanism. For this reason, this is not a feasible solution.

After exploring a variety of options such as the use of proxies to
intercept messages, an approach based on code injection was chosen.
This solution has the advantage of encapsulating the concern in a
new unit while the code that it is finally executed after the injection
is similar to the original code of \emph{Mondrian}. So, the performance
is not affected. In order to encapsulate the source code related with
the code patterns the \emph{pragma} mechanism is used. \emph{Pragmas}
are the method annotation syntax implemented by Pharo.

The refactoring strategy used is: for each method that contains code
related to the \emph{Cache Concern}, the code related to the concern
is extracted using a pragma that is defined in the method. The decision
to define the pragma inside the method is in order to allow a better
visibility of the code that is injected. The pragmas used have a structure
according to each code pattern.\emph{ }In general, the pragmas structure
is \emph{$<$patternCodeName: cacheName$>$} where \emph{cacheName}
indicates the name of the cache that will be injected and \emph{patternCodeName}
indicates the pattern code to be generated. For example, the pragma
\emph{$<$LazyInitializationPattern: \#absoluteBoundsCache$>$} indicates
that the \emph{Lazy Initialization} pattern will be injected for the cache
\emph{absoluteBoundsCache} in the method in which the pragma is defined. \ab{it also creates a variable in the class doesn't it?} \sv{No, the only addition into the original method is the pragma}

Once that the cache code is extracted into the pragmas, the code to
be injected is automatically generated before the execution of the
system. Specifically, the automatic injection of a pragma in a method
is achieved following the next steps: 
\begin{enumerate}
\item A new method is created with the same name that the method that contains
the pragma but with the prefix {}``compute'' plus the name of the
class in which is defined. For example, given the next method
\begin{lstlisting} 
MOGraphElement>>absoluteBounds
	<LazyInitializationPattern: #absoluteBoundsCache> 
	^ self shape absoluteBoundsFor: self
\end{lstlisting}
a new method called \ct{computeMOGraphElementAbsoluteBounds} is created.
\item The code of the original method is copied into the new method.
\begin{lstlisting} 
MOGraphElement>>computeMOGraphElementAbsoluteBounds
	^ self shape absoluteBoundsFor: self
\end{lstlisting}
\item The code inside the original method is replaced by the code automatically
generated according to the pattern defined in the pragma. This generated
method contains a call to the new method of the Step 1.
\begin{lstlisting} 
MOGraphElement>>absoluteBounds
	absoluteBoundsCache 
		ifNotNil: [ ^ absoluteBoundsCache].
	^ absoluteBoundsCache:=
		(self computeMOGraphElementabsoluteBounds)
\end{lstlisting}
\end{enumerate}
In this way, the refactored cache code is executed with Mondrian.

In order to automatically generate the code to be injected, the injector
code mechanism provides a \emph{CachePattern} interface. In this way,
each cache pattern has to implements this interface which allow the
generation of the methods mentioned above. Basically each subclass
is responsible of the definition of the pragma to be used and the
generation of the code sentences to be injected related with the cache
whereas the interface \emph{CachePattern} creates the methods to be
added to the system. This class hierarchy is shown in Fig. \ref{fig:Pattern-hierarchy.}.
%
\begin{figure*}
\begin{centering}
\includegraphics[bb=21bp 541bp 561bp 789bp,scale=0.7]{PatternInheritance}
\par\end{centering}

\caption{Pattern hierarchy.\label{fig:Pattern-hierarchy.}}

\end{figure*}


Next, the refactorings applied to each code pattern are presented.

\paragraph{Reset Cache.} In order to refactor this pattern each statement
that resets a cache was extracted using a pragma. The pragma contains
the cache to be resetted. Owing to in some cases the resets are done
at the beginning of a method and others at the end, a hierarchy of
Reset Cache pattern is created. As is shown in Fig. \ref{fig:Pattern-hierarchy.},
this hierarchy is composed of the classes \emph{AbstractResetCachePattern},
\emph{BeforeResetCachePattern}, and \emph{AfterResetCachePattern}.
The pragmas are defined in the classes at the bottom of the hierarchy
as $<$BeforeResetCachePattern: cacheName$>$ and $<$AfterResetCachePattern:
cacheName$>$ respectively. For example, in the case presented in Section
\ref{sub:Pattern-Identification} of the method \emph{resetCache},
a pragma is defined for each reset of a cache leaving a cleaner code
in the method. In this case all the resets are done before the method
call, so the pragmas used are the defined by \emph{BeforeResetCachePattern}.
Even though the order of calls is changed (in comparison with the
original method), the method behavior is not modified. The code to
be generated will reset the cache defined
in the pragma. Following, the refactored code is presented:

\begin{lstlisting} 
MOGraphElement>>resetCache 
	<BeforeResetCachePattern: #absoluteBoundsCache> 
	<BeforeResetCachePattern: #elementsToDisplayCache>
	<BeforeResetCachePattern: #boundsCache> 
	<BeforeResetCachePattern: #cacheShapeBounds> 
	self resetElementsToLookup. 
	self resetMetricCaches
\end{lstlisting}

The methods \emph{resetElementsToLookup} and \emph{resetMetricCaches} 
performs additional activities that do not involve the cache variables. For this reason they remain in the \emph{resetCache} method.

After the code injection the resetCache method is transformed into:

\begin{lstlisting} 
MOGraphElement>>resetCache 
	absoluteBoundsCache:=nil.
	elementsToDisplayCache:=nil. 
	boundsCache:=nil. 
	cacheShapeBounds:=SmallDictionary new. 
	self computeMOGraphElementresetCache 
\end{lstlisting}

where the method computeMOGraphElementresetCache is:

\begin{lstlisting} 
MOGraphElement>>computeMOGraphElementresetCache
	self resetElementsToLookup. 
	self resetMetricCaches 
\end{lstlisting}

This mechanism of injection of the generated code is the same for
the rest of the patterns.

\paragraph{Lazy Initialization.} To refactor this pattern
the precondition checking is encapsulated into a pragma defined as
$<$LazyInitializationPattern: cacheName$>$. Given that
the cache is initialized with a value when the precondition fails,
the original method is modified to return this value. For example,
in the case of the \emph{bounds} method presented in the previous
section, the code related to the cache is extracted using the pragma
and only the value to initialize the cache remains in the method as
shown the code below:

\begin{lstlisting} 
MOEdge>>bounds 
	<LazyInitializationPattern: #boundsCache> 
	self shape computeBoundsFor: self. 
\end{lstlisting}

In this way, the code to be generated for this example will be \emph{boundsCache
ifNotNil: {[} \textasciicircum{} boundsCache{]}. \textasciicircum{}
boundsCache:= computeMOEdgeBounds.}

\paragraph{Cache Initialization.} The refactorization of this cache is
similar to the last one. Given that the structure of the pattern is
an assignation, the first section of the assignation (\emph{cacheName:=})
will be generated automatically by the code injection mechanism using
a pragma defined as $<$CacheInitializationPattern: cacheName$>$.
So, only the value at which is initialized remains in the method.
In the case of the example presented in Section \ref{sub:Pattern-Identification},
the refactored code is shown below:

\begin{lstlisting} 
MOGraphElement>>cacheCanvas: aCanvas 
	<CacheInitializationPattern: #cacheForm>  
	(aCanvas form copy: ((self bounds origin + aCanvas origin
	- (1@1)) extent: (self bounds extent + (2@2)))). 
\end{lstlisting}

\paragraph{Return Cache.} In this refactorization the entire return clause
is encapsulated by the pragma. The pragma is defined as $<$ReturnCachePattern:
cacheName$>$. Following, the refactored code for the example shown in
the last section is presented:

\begin{lstlisting}
 MOGraphElement>>shapeBounds 
	<ReturnCachePattern: #cacheShapeBounds> 
\end{lstlisting}

\paragraph{Cache Loaded.} In order to refactor this pattern the cache checking
is encapsulated by a pragma defined as $<$CacheLoadedPattern:
cacheName$>$. The code generated contains a sentence in which the checking
is done for all the caches defined in the pragmas of this pattern
contained in a method. In the case of the example presented in Section
\ref{sub:Pattern-Identification}, the refactored code is shown below:
\begin{lstlisting} 
MOGraphElement>>isCacheLoaded 
	<CacheLoadedPattern: #cacheForm>
\end{lstlisting}

With the use of these patterns the \emph{Cache Concern} is refactorized
properly in more than 85\% of the methods of the \ct{MOGraphElement} hierarchy that uses one or more caches. \ab{Does it mean that 85\% of Mondrian methods use a cache?} \sv{No, I mean that from all the methods that uses a cache 85\% could be refactored with the pattern structure}
The main reason because some of the uses of the caches are not encapsulated by means of 
cache patterns are (1) the code belongs to a cache pattern but the code related with the cache is too mixed 
with the main concern, or (2) the code does not match with any of the patterns described. For example the method
\begin{lstlisting} 
MOGraphElement>>nodeWith: anObject ifAbsent: aBlock  
	| nodeLookedUp |
	lookupNodeCache ifNil: [ lookupNodeCache := IdentityDictionary new ].
	lookupNodeCache at: anObject ifPresent: [ :v | ^ v ].
	nodeLookedUp := self nodes detect: [:each | each model = anObject ] ifNone: aBlock.
	lookupNodeCache at: anObject put: nodeLookedUp.
	^ nodeLookedUp
\end{lstlisting}
could not been refactored because the cache \emph{lookupNodeCache} is used to make different computations across the whole
method by which is closely tied to the main concern. 
These uses of the caches that are not encapsulated
by patterns are also refactored by means of pragmas. For these cases
a \emph{Generic AOP} pattern is used. The pragmas used have the structure
\emph{$<$cache: cacheName before: '' after: ''$>$} where \emph{cache}
indicates the name of the cache that will be injected. The clauses
before and after indicate the source code that will be injected and
when it will be injected in regard to the execution of the method.
That is to say, the code inside the original method will be replaced
by the code pointed out in the before clause of the pragma, a call
to the new method will be added, and the code contained in the after
clause of the pragma will be added at the end. For example, the refactorization of the method presented previously is
\begin{lstlisting} 
MOGraphElement>>nodeWith: anObject ifAbsent: aBlock  
	<cache: #lookupNodeCache before:'	lookupNodeCache ifNil: [lookupNodeCache := IdentityDictionary new ]. 			
	lookupNodeCache at: anObject ifPresent: [ :v | ^ v ]. 
	^lookupNodeCache at: anObject put: (' after: ' )'>
	| nodeLookedUp |
	nodeLookedUp := self nodes detect: [:each | each model = anObject ] ifNone: aBlock.
	^ nodeLookedUp
\end{lstlisting}
As can be seen, all the setences with references to the cache  \emph{lookupNodeCache} are encapsulated into the before clause of the pragma.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Results}\seclabel{results}

\ab{We also need to provide some benchmarks. There is a class in mondrian that does exactly this}

\ab{We need to be stronger on this section}

The use of the presented patterns could be used to compose the caches
behavior improving the maintenance of the system. In this line, the
contribution of the approach is twofold. First, the mechanism of encapsulation
and injection could be used to refactor the currently Mondrian caches
(and also those that may be introduced in future) improving the code
reuse. Second, the code legibility is increased because the \emph{Cache
Concern} is extracted from the main concern leaving a cleaner code.

The cache composition is achieved during the injection phase. As the
different pieces of code that are related to the cache are encapsulated
by means of the patterns, an implicit process of division of the complexity
of the caches behavior is achieved. That is to say, this kind of approach
helps the developer by splitting the caches behavior is smalls fragments
of code. These fragments of code are encapsulated by the patterns
and they are finally composed during the injection phase. For example,
the functionality related to the cache \emph{absoluteBoundsCache}
is refactored by the patterns \emph{Reset Cache,} \emph{Lazy Initialization}, and \emph{Cache Initialization}.

One of the main priorities during the refactoring process was not to affect the performance of the system. 
For this reason a group of benchmarks were measured in order to evaluate the cache performance when a set of nodes and edges are displayed. The variations observed between the system before and after applying refactorings are not significant. That is because, in general, the code after the injection of the caches is the same that the original code before the Mondrian refactoring. The details of the benchmarks results can be found in the appendix. 

\paragraph{Using cache in the main logic}
This experience has been the opportunity to rethink on the implementation of Mondrian. We found one occurrence where a cache variable is not solely used as a cache, but as part of main logic of Mondrian. The method bounds contains an access to \ct{boundsCache}: 

\begin{lstlisting} 
MOGraphElement >>bounds
	...
	self shapeBoundsAt: self shape ifPresent: [ :b | ^ boundsCache := b ].
	...
\end{lstlisting}

\begin{lstlisting} 
MOGraphElement >>translateAbsoluteCacheBy: aPoint
	absoluteBoundsCache ifNil: [ ^ self ].
	absoluteBoundsCache := absoluteBoundsCache translateBy: aPoint
\end{lstlisting}

The core of Mondrian is not independent of the cache implementation. The logic of Mondrian rely on the cache to implement its semantics. This is obviously wrong and this is situation is marked as a defect\footnote{\url{http://code.google.com/p/moose-technology/issues/detail?id=501}}.

\paragraph{Singularity of \co{\#displayOn:}} Displaying a node uses all the defined caches to have a fast rendering. We were not able to define \co{\#displayOn:} as the result of an automatic composition. The main problem is that this method uses intensively the cache to load and save data during its execution. For this reason, the code related to the cache is very scattered across the method  making the restructuration of it by mean of cache patterns almost unviable. So, this method was restructured using the Generic AOP pattern. 

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Discussion}\seclabel{discussion}

\ab{What are the benefits of the approach? Can I unplug cache?}

The injection mechanism may reorder statements in the instrumented method. This is the case of the reset method (which was presented in the previous section). As was shown, in this case the caches are resetted at the beginning of the method and after that the method \emph{resetElementsToLookup} and \emph{resetMetricCaches} are invocated in contrast with the original method in which the former was invocated at the beginning and the former at the end. Even though the order of calls is changed the behavior of the method is not modified. The consistent behavior was checked in a manual way and by mean of automatic test.

\ab{How many occurrences of statement reordering?}

However, in practice, this has not caused any noticeable problem. The extensive test set of Mondrian remained green after the instrumentation.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Conclusion}\seclabel{conclusion}



% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section*{Acknowledgments}

\small We gratefully thanks ...

% bibliography
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\bibliographystyle{abbrvnat}
\bibliography{scg}

\begin{table*}
\begin{centering}
\begin{tabular}{|>{\centering}p{1.8cm}|c|>{\centering}p{4cm}|>{\centering}p{4cm}|}
\hline 
Kind of benchmark & Nodes/Nodes & Time before refactorization (ms) & Time after refactorization (ms)\tabularnewline
\hline
\hline 
Nodes & 100  & 13 & 13\tabularnewline
\cline{2-4} 
 & 200 & 23 & 21\tabularnewline
\cline{2-4} 
 & 300 & 23 & 18\tabularnewline
\cline{2-4} 
 & 400 & 25 & 26\tabularnewline
\cline{2-4} 
 & 500 & 30 & 32\tabularnewline
\cline{2-4} 
 & 600 & 35 & 38\tabularnewline
\cline{2-4} 
 & 700 & 41 & 44\tabularnewline
\cline{2-4} 
 & 800 & 47 & 50\tabularnewline
\cline{2-4} 
 & 900 & 53 & 57\tabularnewline
\cline{2-4} 
 & 1000 & 59 & 63\tabularnewline
\cline{2-4} 
 & 1600 & 110 & 102 \tabularnewline
\cline{2-4} 
 & 3200 & 256 & 209 \tabularnewline
\cline{2-4} 
 & 6400 & 382 & 410 \tabularnewline
\hline 
Edges & 10 & 2 & 2\tabularnewline
\cline{2-4} 
 & 20 & 7 & 8\tabularnewline
\cline{2-4} 
 & 30 & 16 & 17\tabularnewline
\cline{2-4} 
 & 40 & 37 & 37\tabularnewline
\cline{2-4} 
 & 50 & 121 & 43\tabularnewline
\cline{2-4} 
 & 60 & 63 & 83\tabularnewline
\cline{2-4} 
 & 70 & 83 & 150\tabularnewline
\cline{2-4} 
 & 80 & 110 & 109 \tabularnewline
\cline{2-4} 
 & 90 & 143 & 149 \tabularnewline
\cline{2-4} 
 & 100 & 269 & 192 \tabularnewline
\cline{2-4} 
 & 200 & 1132 & 1195 \tabularnewline
\cline{2-4} 
 & 300 & 4122 & 3645\tabularnewline
\hline 
Inner nodes & 5 & 159 & 159\tabularnewline
\cline{2-4} 
 & 10 & 2190 & 2212\tabularnewline
\cline{2-4} 
 & 15 & 10564 & 10666\tabularnewline
\hline 
Displaying  & 5 & 230 & 298\tabularnewline
\cline{2-4} 
inner nodes & 10 & 948 & 965\tabularnewline
\cline{2-4} 
 & 15 & 10314 & 10053 \tabularnewline
\hline 
Displaying  & 1 & 10 & 9\tabularnewline
\cline{2-4} 
inner nodes & 2 & 270 & 260\tabularnewline
\cline{2-4} 
and edges & 3 & 3827 & 3677\tabularnewline
\cline{2-4} 
 & 4 & 37536 & 36337 \tabularnewline
\hline 
Displaying & 100 & 4 & 5\tabularnewline
\cline{2-4} 
elementAt & 500 & 6 & 7\tabularnewline
\cline{2-4} 
 & 1000 & 10 & 10\tabularnewline
\cline{2-4} 
 & 1500 & 13 & 13\tabularnewline
\cline{2-4} 
 & 2000 & 16 & 17\tabularnewline
\cline{2-4} 
 & 2500 & 19 & 20\tabularnewline
\hline 
Small nodes & 2000 & 3738 & 3685\tabularnewline
\hline 
Edges bounds & 500 & 161 & 156\tabularnewline
\hline 
Subnodes lookup & 20000 & 4736 & 4624\tabularnewline
\hline
\end{tabular}
\par\end{centering}

\caption{Benchmark of perfomance.\label{tab:Benchmark-of-perfomance.}}



\end{table*}


\end{document}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\begin{lstlisting} 
MOGraphElement>>cacheCanvas: aCanvas 
	<cache: #cacheForm before: 'cacheForm :=' after: ''> 
	^(aCanvas form copy: ((self bounds origin + aCanvas origin - (1@1)) 
	extent: (self bounds extent + (2@2)))). 
\end{lstlisting}

\paragraph{Return Cache.} In this refactorization the entire return clause
is encapsulated into the pragma. The after clause is used to contain
the code because some computations can be performed before returning
the cache. Following, the refactored code for the example presented
in the last section is presented:

\begin{lstlisting} 
MOGraphElement>>shapeBounds 
	<cache: #cacheShapeBounds before: '' after: '.^ cacheShapeBounds.'> 
\end{lstlisting}

\paragraph{What we would like to have}\ \\
The programmer, instead of writting:
\begin{lstlisting}
MOGraphElement>>absoluteBounds
	absoluteBoundsCache ifNotNil: [ ^ absoluteBoundsCache ].
	^ absoluteBoundsCache := self shape absoluteBoundsFor: self
\end{lstlisting}

He/She should write:

\begin{lstlisting}
MOGraphElement>>absoluteBounds
	<cache: #absoluteBoundsCache>
	 ^ self shape absoluteBoundsFor: self
\end{lstlisting}

Then, our cache injector mechanism will produce the code:
\begin{lstlisting}
MOGraphElement>>absoluteBounds
	<instrumented>
	<cache: #absoluteBoundsCache>
	absoluteBoundsCache ifNotNil: [ ^ absoluteBoundsCache ].
	 ^ absoluteBoundsCache  := self  computeAbsoluteBounds.
	
MOGraphElement>> computeAbsoluteBounds
	^ self shape absoluteBoundsFor: self
\end{lstlisting}



\paragraph{What we have now in our implementation}

The code
\begin{lstlisting}
MOGraphElement>>absoluteBounds
	"Answer the bounds in absolute terms (relative to the entire Canvas, not just the parent)."
	absoluteBoundsCache ifNotNil: [ ^ absoluteBoundsCache ].
	^ absoluteBoundsCache := self shape absoluteBoundsFor: self
\end{lstlisting}

is transformed into 

\begin{lstlisting}
MOGraphElement>>absoluteBounds
<cache: #absoluteBoundsCache before: 'absoluteBoundsCache ifNotNil: [ ^ absoluteBoundsCache ]. ^ absoluteBoundsCache := (' after: ' )'>
	"Answer the bounds in absolute terms (relative to the entire Canvas, not just the parent)."
	 ^ self shape absoluteBoundsFor: self
\end{lstlisting}

\begin{lstlisting}
bounds
	"Answer the bounds of the receiver."
	"the bounds is has an absolute origin"
	"Note that the bounds computed above, may have (and it is likely to) a different origin. The reason is that the layout is in charge to position the nodes properly"
	| basicBounds |

	boundsCache ifNotNil: [ ^ boundsCache ].

	"We check if  the shape if present"
	self shapeBoundsAt: self shape ifPresent: [ :b | ^ boundsCache := b ].

	basicBounds := self shape computeBoundsFor: self.
	self shapeBoundsAt: self shape put: basicBounds.
	^ boundsCache := basicBounds
\end{lstlisting}

is refactorized into:

\begin{lstlisting}
bounds
<cache: #boundsCache before: 'boundsCache ifNotNil: [ ^ boundsCache ]. self shapeBoundsAt: self shape ifPresent: [ :b | ^ boundsCache := b ]. ^ boundsCache :=' after: ''>
	"Answer the bounds of the receiver."
	"the bounds is has an absolute origin"
	"Note that the bounds computed above, may have (and it is likely to) a different origin. The reason is that the layout is in charge to position the nodes properly"
	| basicBounds |
	basicBounds := self shape computeBoundsFor: self.
	self shapeBoundsAt: self shape put: basicBounds.
	^ basicBounds
\end{lstlisting}

\begin{lstlisting}
cacheCanvas: aCanvas
	cacheForm := aCanvas form copy: ((self bounds origin + aCanvas origin - (1@1)) 
													extent: (self bounds extent + (2@2))).
\end{lstlisting}

is transformed into:

\begin{lstlisting}
cacheCanvas: aCanvas
<cache: #cacheForm before: 'cacheForm :=' after: ''>
	^(aCanvas form copy: ((self bounds origin + aCanvas origin - (1@1)) 
													extent: (self bounds extent + (2@2)))).
\end{lstlisting}


\begin{lstlisting}
elementsToDisplay

	elementsToDisplayCache ifNotNil: [ ^ elementsToDisplayCache ].
	^ elementsToDisplayCache := self computeElementsToDisplay
\end{lstlisting}

is transformed into:

\begin{lstlisting}
elementsToDisplay
<cache: #elementsToDisplayCache before: 'elementsToDisplayCache ifNotNil: [ ^ elementsToDisplayCache ]. ^ elementsToDisplayCache := (' after: ' )'>
^ self compute2ElementsToDisplay
\end{lstlisting}	

\begin{lstlisting}
hasCachedForm
	^ cacheForm notNil
\end{lstlisting}	

transformed into:

\begin{lstlisting}
hasCachedForm
<cache: #cacheForm before: '' after: '.^ cacheForm notNil.'>
\end{lstlisting}	

\begin{lstlisting}
nodeWith: anObject ifAbsent: aBlock 
	| nodeLookedUp |
	lookupNodeCache ifNil: [ lookupNodeCache := IdentityDictionary new ].
	lookupNodeCache at: anObject ifPresent: [ :v | ^ v ].
	nodeLookedUp := self nodes detect: [:each | each model = anObject ] ifNone: aBlock.
	lookupNodeCache at: anObject put: nodeLookedUp.
	^ nodeLookedUp
\end{lstlisting}

\begin{lstlisting}
nodeWith: anObject ifAbsent: aBlock 
<cache: #lookupNodeCache before:'	lookupNodeCache ifNil: [ lookupNodeCache := IdentityDictionary new ]. lookupNodeCache at: anObject ifPresent: [ :v | ^ v ]. ^lookupNodeCache at: anObject put: (' after: ' )'>
	^ self nodes detect: [:each | each model = anObject ] ifNone: aBlock.
\end{lstlisting}


\begin{lstlisting}
resetCache
	self resetElementsToLookup.
	boundsCache := absoluteBoundsCache := nil.	"Having IdentityDictionary instead of SmallDictionary works the same, it is faster although"
	cacheShapeBounds := SmallDictionary new.	"cacheShapeBounds := IdentityDictionary new"
	elementsToDisplayCache := nil.
	self resetMetricCaches
\end{lstlisting}
transformed into:
\begin{lstlisting}
resetCache
<cache: #absoluteBoundsCache before: 'absoluteBoundsCache := nil.' after: ''> 
<cache: #elementsToDisplayCache before: 'elementsToDisplayCache := nil.' after: ''> 
<cache:#boundsCache before: 'boundsCache:= nil.' after: ''> 
<cache: #cacheShapeBounds before: 'cacheShapeBounds := SmallDictionary new.' after: ''>

	self resetElementsToLookup.
	self resetMetricCaches
\end{lstlisting}

\begin{lstlisting}
MONode>>displayOn: aCanvas 
	"	self layer isVisible ifFalse: [ ^ self ]."	
	| b canvas |
	(aCanvas isVisible: self absoluteBounds) ifFalse: [ ^ self ].

	self isCacheLoaded ifTrue: [
		aCanvas paintImage: cacheForm at: (self absoluteBounds origin - (1@1)).
		^ self ].
	
	self shouldCache ifFalse: [ 
		"If we cannot cache (for example if we are too big) then we display ourself, and iterate over inner nodes
		 while giving them a chance to cache"
		self displayWithoutCachingOn: aCanvas.
		^ self ].	
	
	b := self bounds.	
	canvas := FormCanvas extent: (b extent + (2@2)) .

	canvas 
		translateBy: self absoluteBounds origin negated + (1@1) 
		during: [:tmpCanvas | self displayWithoutCachingOn: tmpCanvas ].
	cacheForm := canvas form.	

	self updateOwner. 
	aCanvas paintImage: cacheForm at: (self absoluteBounds origin - (1@1)).
\end{lstlisting}

\begin{lstlisting}
MONode>>displayOn: aCanvas 
<cache: #cacheForm before: '(aCanvas isVisible: self absoluteBounds) ifFalse: [ ^ self ]. self isCacheLoaded ifTrue: [
		aCanvas paintImage: cacheForm at: (self absoluteBounds origin - (1@1)).
		^ self ]. self shouldCache ifFalse: [ self displayWithoutCachingOn: aCanvas. ^ self ]. cacheForm := ' after: '.self updateOwner. 
	aCanvas paintImage: cacheForm at: (self absoluteBounds origin - (1@1)).'>

	| b canvas |
	b := self bounds.	
	canvas := FormCanvas extent: (b extent + (2@2)) .
		
	canvas 
		translateBy: self absoluteBounds origin negated + (1@1) 
		during: [:tmpCanvas | self displayWithoutCachingOn: tmpCanvas ].
	^ canvas form.	
\end{lstlisting}

\begin{lstlisting}
translateBy: aPoint bounded: bounded
	"It moves the element by aPoint. 
	If bounded is true and the owner is not the root, 
	then the bounds are limited by the owner bounds.
	If the element is placed in the root, then the root's bounds are updated"
	| realStep newRelativePosition allShapes |
	self shapeBounds isNil ifTrue: [ ^ self bounds ].
	self shapeBounds isEmpty ifTrue: [ ^ self bounds ].

	realStep :=  bounded 
						ifTrue: [ self getBoundedTranslationStep: aPoint ]
						ifFalse: [ aPoint ].			

	newRelativePosition := self origin + aPoint.	

	allShapes := self shapeBounds keys.
	allShapes do: [ :eachShape | 
		self shapeBoundsAt: eachShape put: ((self shapeBoundsAt: eachShape) translateBy: realStep) ].
	boundsCache := absoluteBoundsCache := nil.
	self allNodesDo: [ :n | n translateAbsoluteCacheBy: realStep ].

	
	owner isRoot ifTrue: [
		"the root has to be extended in any case"
		owner expandToIncludePoint: (newRelativePosition +  self bounds extent) ].
	
	self resetCacheInEdges
\end{lstlisting}

\begin{lstlisting}
translateBy: aPoint bounded: bounded
<cache: #boundsCache before: '' after: '.boundsCache :=nil.'>
<cache: #absoluteBoundsCache before: '' after: 'absoluteBoundsCache := nil.'>
	"It moves the element by aPoint. 
	If bounded is true and the owner is not the root, 
	then the bounds are limited by the owner bounds.
	If the element is placed in the root, then the root's bounds are updated"
	| realStep newRelativePosition allShapes |
	self shapeBounds isNil ifTrue: [ ^ self bounds ].
	self shapeBounds isEmpty ifTrue: [ ^ self bounds ].

	realStep :=  bounded 
						ifTrue: [ self getBoundedTranslationStep: aPoint ]
						ifFalse: [ aPoint ].			

	newRelativePosition := self origin + aPoint.	

	allShapes := self shapeBounds keys.
	allShapes do: [ :eachShape | 
		self shapeBoundsAt: eachShape put: ((self shapeBoundsAt: eachShape) translateBy: realStep) ].
	
	owner isRoot ifTrue: [
		"the root has to be extended in any case"
		owner expandToIncludePoint: (newRelativePosition +  self bounds extent) ].
	
	
	"boundsCache := absoluteBoundsCache := nil."
	self allNodesDo: [ :n | n translateAbsoluteCacheBy: realStep ].
	self resetCacheInEdges
\end{lstlisting}

\begin{lstlisting}
NONode>>bounds
	^ boundsCache ifNil: [ boundsCache := self shape computeBoundsFor: self ].
\end{lstlisting}

\begin{lstlisting}
NONode>>bounds
<cache: #boundsCache before: '^ boundsCache ifNil: [boundsCache :=' after: ' ]'>
	^self shape computeBoundsFor: self.
\end{lstlisting}
